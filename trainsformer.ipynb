{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    대분류 소분류       상황  Set Nr.  발화자                            원문  \\\n",
      "0  비즈니스  회의  의견 교환하기        1  A-1   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
      "1  비즈니스  회의  의견 교환하기        1  B-1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
      "2  비즈니스  회의  의견 교환하기        1  A-2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
      "3  비즈니스  회의  의견 교환하기        1  B-2   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
      "4  비즈니스  회의  의견 교환하기        2  A-1   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
      "\n",
      "                                                 번역문  \n",
      "0  How is the market's reaction to the newly rele...  \n",
      "1  The sales increase is faster than the previous...  \n",
      "2  Then, we'll have to call the manufacturer and ...  \n",
      "3  Sure, I'll make a call and double the volume o...  \n",
      "4  Shall we take a look at the issues we discusse...  \n"
     ]
    }
   ],
   "source": [
    "data_path = \"./Korean-English/2_대화체.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, '원문'], self.data.loc[idx, '번역문']\n",
    "\n",
    "custom_DS = CustomDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] PositionalEncoding  \n",
    "[2] MultiHeadAttention  \n",
    "[3] FeedForward  \n",
    "[4] EncoderLayer  \n",
    "[5] DecoderLayer  \n",
    "[6] Encoder  \n",
    "[7] Decoder  \n",
    "[8] Transformer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.Models import Transformer\n",
    "from transformer.Optim import ScheduledOptim\n",
    "from utils.argument_parser import get_args\n",
    "import os\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_src(src, pad_idx):\n",
    "    src = src.transpose(0, 1)\n",
    "    return src\n",
    "\n",
    "\n",
    "def patch_trg(trg, pad_idx):\n",
    "    trg = trg.transpose(0, 1)\n",
    "    trg, gold = trg[:, :-1], trg[:, 1:].contiguous().view(-1)\n",
    "    return trg, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = get_args()\n",
    "opt.cuda = not opt.no_cuda\n",
    "opt.d_word_vec = opt.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] The warmup steps may be not enough.\n",
      "(sz_b, warmup) = (2048, 4000) is the official setting.\n",
      "Using smaller batch w/o longer warmup may cause the warmup stage ends with only little data trained.\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "if opt.seed is not None:\n",
    "    torch.manual_seed(opt.seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.set_deterministic(True)\n",
    "    np.random.seed(opt.seed)\n",
    "    random.seed(opt.seed)\n",
    "\n",
    "if not opt.output_dir:\n",
    "    print('No experiment result will be saved.')\n",
    "\n",
    "if not os.path.exists(opt.output_dir):\n",
    "    os.makedirs(opt.output_dir)\n",
    "\n",
    "if opt.batch_size < 2048 and opt.n_warmup_steps <= 4000:\n",
    "    print('[Warning] The warmup steps may be not enough.\\n'\\\n",
    "            '(sz_b, warmup) = (2048, 4000) is the official setting.\\n'\\\n",
    "            'Using smaller batch w/o longer warmup may cause '\\\n",
    "            'the warmup stage ends with only little data trained.')\n",
    "\n",
    "device = torch.device('cuda' if opt.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer.Constants as Constants\n",
    "\n",
    "# 1. 전체 문장 모으기\n",
    "all_src_sentences = [custom_DS[i][0] for i in range(len(custom_DS))]\n",
    "all_trg_sentences = [custom_DS[i][1] for i in range(len(custom_DS))]\n",
    "\n",
    "# 2. Tokenize (공백 기준으로 단어 분리)\n",
    "src_tokens = [token for sent in all_src_sentences for token in sent.split()]\n",
    "trg_tokens = [token for sent in all_trg_sentences for token in sent.split()]\n",
    "\n",
    "# 3. Special tokens\n",
    "special_tokens = [Constants.PAD_WORD, Constants.BOS_WORD, Constants.EOS_WORD, Constants.UNK_WORD]\n",
    "\n",
    "# 4. Vocab 만들기\n",
    "src_vocab = {token: idx for idx, token in enumerate(special_tokens + sorted(set(src_tokens)))}\n",
    "trg_vocab = {token: idx for idx, token in enumerate(special_tokens + sorted(set(trg_tokens)))}\n",
    "\n",
    "# 5. idx2word 매핑\n",
    "src_idx2word = {idx: word for word, idx in src_vocab.items()}\n",
    "trg_idx2word = {idx: word for word, idx in trg_vocab.items()}\n",
    "\n",
    "# 6. opt 세팅\n",
    "max_src_len = max(len(sent.split()) for sent in all_src_sentences)\n",
    "max_trg_len = max(len(sent.split()) for sent in all_trg_sentences)\n",
    "opt.max_token_seq_len = max(max_src_len, max_trg_len) + 2\n",
    "\n",
    "opt.src_pad_idx = src_vocab[Constants.PAD_WORD]\n",
    "opt.trg_pad_idx = trg_vocab[Constants.PAD_WORD]\n",
    "opt.src_vocab_size = len(src_vocab)\n",
    "opt.trg_vocab_size = len(trg_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "길이: 100000\n",
      "예시: ['이번 신제품 출시에 대한 시장의 반응은 어떤가요?', '판매량이 지난번 제품보다 빠르게 늘고 있습니다.', '그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.', '네, 제가 연락해서 주문량을 2배로 늘리겠습니다.', '지난 회의 마지막에 논의했던 안건을 다시 볼까요?']\n",
      "['이번', '신제품', '출시에', '대한', '시장의', '반응은', '어떤가요?', '판매량이', '지난번', '제품보다']\n",
      "전체 단어 수: 779,541\n",
      "고유 단어 수: 117,299\n",
      "0: <blank> → 0\n",
      "1: <s> → 1\n",
      "2: </s> → 2\n",
      "3: <unk> → 3\n",
      "4: \"국어학 → 4\n",
      "5: \"나는 → 5\n",
      "0: <blank> → 0\n",
      "1: <s> → 1\n",
      "2: </s> → 2\n",
      "3: <unk> → 3\n",
      "4: \"Animal → 4\n",
      "5: \"Be → 5\n"
     ]
    }
   ],
   "source": [
    "print(\"길이:\", len(all_src_sentences))\n",
    "print(\"예시:\", all_src_sentences[:5])\n",
    "\n",
    "print(src_tokens[:10])  # 앞의 10개 단어만 확인\n",
    "print(f\"전체 단어 수: {len(src_tokens):,}\")\n",
    "print(f\"고유 단어 수: {len(set(src_tokens)):,}\")\n",
    "\n",
    "for i, (token, idx) in enumerate(src_vocab.items()):\n",
    "    print(f\"{i}: {token} → {idx}\")\n",
    "    if i >= 5:  # 앞에서 5개만 출력\n",
    "        break\n",
    "\n",
    "for i, (token, idx) in enumerate(trg_vocab.items()):\n",
    "    print(f\"{i}: {token} → {idx}\")\n",
    "    if i >= 5:  # 앞에서 5개만 출력\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split\n",
    "total_size = len(custom_DS)\n",
    "train_size = int(total_size * 0.8)\n",
    "val_size = int(total_size * 0.1)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(custom_DS, [train_size, val_size, test_size])\n",
    "\n",
    "# 2. collate_fn\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    \n",
    "    src_indices = []\n",
    "    trg_indices = []\n",
    "    for src_sent, trg_sent in zip(src_batch, trg_batch):\n",
    "        src = [src_vocab.get(token, src_vocab[Constants.UNK_WORD]) for token in src_sent.split()]\n",
    "        trg = [trg_vocab.get(token, trg_vocab[Constants.UNK_WORD]) for token in trg_sent.split()]\n",
    "\n",
    "        src = [src_vocab[Constants.BOS_WORD]] + src + [src_vocab[Constants.EOS_WORD]]\n",
    "        trg = [trg_vocab[Constants.BOS_WORD]] + trg + [trg_vocab[Constants.EOS_WORD]]\n",
    "\n",
    "        src_indices.append(torch.tensor(src, dtype=torch.long))\n",
    "        trg_indices.append(torch.tensor(trg, dtype=torch.long))\n",
    "\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_indices, batch_first=True, padding_value=src_vocab[Constants.PAD_WORD])\n",
    "    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_indices, batch_first=True, padding_value=trg_vocab[Constants.PAD_WORD])\n",
    "\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "# 3. DataLoader\n",
    "train_DL = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_DL = DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_DL = DataLoader(test_dataset, batch_size=opt.batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    opt.src_vocab_size,\n",
    "    opt.trg_vocab_size,\n",
    "    src_pad_idx=opt.src_pad_idx,\n",
    "    trg_pad_idx=opt.trg_pad_idx,\n",
    "    trg_emb_prj_weight_sharing=opt.proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=opt.embs_share_weight,\n",
    "    d_k=opt.d_k,\n",
    "    d_v=opt.d_v,\n",
    "    d_model=opt.d_model,\n",
    "    d_word_vec=opt.d_word_vec,\n",
    "    d_inner=opt.d_inner_hid,\n",
    "    n_layers=opt.n_layers,\n",
    "    n_head=opt.n_head,\n",
    "    dropout=opt.dropout,\n",
    "    scale_emb_or_prj=opt.scale_emb_or_prj).to(device)\n",
    "\n",
    "optimizer = ScheduledOptim(\n",
    "        optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "        opt.lr_mul, opt.d_model, opt.n_warmup_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def patch_src(src, pad_idx):\n",
    "    return src\n",
    "\n",
    "\n",
    "def patch_trg(trg, pad_idx):\n",
    "    trg, gold = trg[:, :-1], trg[:, 1:].contiguous().view(-1)\n",
    "    return trg, gold\n",
    "\n",
    "\n",
    "def cal_performance(pred, gold, pad_idx):\n",
    "    gold = gold.contiguous().view(-1)\n",
    "    pred = pred.view(-1, pred.size(-1))\n",
    "    \n",
    "    non_pad_mask = gold.ne(pad_idx)\n",
    "    n_correct = pred.max(1)[1].eq(gold).masked_select(non_pad_mask).sum().item()\n",
    "    n_word = non_pad_mask.sum().item()\n",
    "\n",
    "    loss = F.cross_entropy(pred, gold, ignore_index=pad_idx, reduction='sum')\n",
    "    return loss, n_correct, n_word\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, opt, device):\n",
    "    ''' 한 epoch 동안 학습하는 함수 (tqdm 추가 버전) '''\n",
    "    model.train()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
    "\n",
    "    desc = '  - (Training)   '\n",
    "    for src_seq, trg_seq in tqdm(train_loader, mininterval=2, desc=desc, leave=False):\n",
    "       \n",
    "        src_seq = patch_src(src_seq, opt.src_pad_idx).to(device)\n",
    "        trg_seq, gold = map(lambda x: x.to(device), patch_trg(trg_seq, opt.trg_pad_idx))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src_seq, trg_seq)\n",
    "\n",
    "        loss, n_correct, n_word = cal_performance(pred, gold, opt.trg_pad_idx)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step_and_update_lr()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_word_total += n_word\n",
    "        n_word_correct += n_correct\n",
    "\n",
    "    loss_per_word = total_loss / n_word_total\n",
    "    accuracy = n_word_correct / n_word_total\n",
    "    return loss_per_word, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, opt, device):\n",
    "    ''' 한 epoch 동안 검증하는 함수 '''\n",
    "    model.eval()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src_seq, trg_seq in val_loader:\n",
    "\n",
    "            src_seq = patch_src(src_seq, opt.src_pad_idx).to(device)\n",
    "            trg_seq, gold = map(lambda x: x.to(device), patch_trg(trg_seq, opt.trg_pad_idx))\n",
    "\n",
    "            pred = model(src_seq, trg_seq)\n",
    "            loss, n_correct, n_word = cal_performance(pred, gold, opt.trg_pad_idx)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_word_total += n_word\n",
    "            n_word_correct += n_correct\n",
    "\n",
    "    loss_per_word = total_loss / n_word_total\n",
    "    accuracy = n_word_correct / n_word_total\n",
    "    return loss_per_word, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch_i in range(opt.epoch):\n",
    "    print(f'[ Epoch {epoch_i} ]')\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss, train_accu = train_epoch(transformer, train_DL, optimizer, opt, device)\n",
    "    print('  - (Training)   loss: {:.5f}, accuracy: {:.3f} %, elapse: {:.3f} min'.format(\n",
    "        train_loss, 100*train_accu, (time.time()-start)/60))\n",
    "\n",
    "    start = time.time()\n",
    "    val_loss, val_accu = eval_epoch(transformer, val_DL, opt, device)\n",
    "    print('  - (Validation) loss: {:.5f}, accuracy: {:.3f} %, elapse: {:.3f} min'.format(\n",
    "        val_loss, 100*val_accu, (time.time()-start)/60))\n",
    "\n",
    "    # 모델 저장\n",
    "    if epoch_i % 20 == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch_i,\n",
    "            'model': transformer.state_dict(),\n",
    "            'opt': opt,\n",
    "            'src_vocab': src_vocab,\n",
    "            'trg_vocab': trg_vocab\n",
    "        }\n",
    "        torch.save(checkpoint, f'{opt.output_dir}/transformer_epoch{epoch_i}.chkpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformer.Constants as C  # PAD/BOS/EOS\n",
    "\n",
    "# ────────────────────────────────\n",
    "# 1. Causal mask  (B,L) → (B,L,L)\n",
    "# ────────────────────────────────\n",
    "def causal_mask_bf(seq_BL: torch.Tensor) -> torch.Tensor:\n",
    "    B, L = seq_BL.size()\n",
    "    # True == masked  (upper-triangular 제외)\n",
    "    mask = torch.triu(\n",
    "        torch.ones(L, L, dtype=torch.bool, device=seq_BL.device), diagonal=1\n",
    "    )\n",
    "    return mask.unsqueeze(0).expand(B, -1, -1)      # (B,L,L)\n",
    "\n",
    "# ────────────────────────────────\n",
    "# 2. Greedy 디코더  (모델도 batch-first)\n",
    "# ────────────────────────────────\n",
    "@torch.no_grad()\n",
    "def greedy_decode_bf(model, src_BL, opt, device):\n",
    "    \"\"\"\n",
    "    src_BL : (B, L)\n",
    "    반환     : List[List[int]]  (배치별 예측 토큰 시퀀스)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B, _ = src_BL.size()\n",
    "\n",
    "    # ── Encoder ──────────────────\n",
    "    src_mask = (src_BL != opt.src_pad_idx).unsqueeze(1)     # (B,1,L)\n",
    "    enc_out, *_ = model.encoder(src_BL, src_mask)           # (B,L,d)\n",
    "\n",
    "    # ── 디코더 반복 ───────────────\n",
    "    ys = torch.full((B, 1), trg_vocab[C.BOS_WORD],\n",
    "                    dtype=torch.long, device=device)\n",
    "\n",
    "    for _ in range(opt.max_token_seq_len):\n",
    "        tgt_mask = (ys != opt.trg_pad_idx).unsqueeze(1) & causal_mask_bf(ys)\n",
    "        dec_out, *_ = model.decoder(ys, tgt_mask, enc_out, src_mask)  # (B,L',d)\n",
    "\n",
    "        logits   = model.trg_word_prj(dec_out)[:, -1]   # (B,V)\n",
    "        next_tok = logits.argmax(dim=-1, keepdim=True) # (B,1)\n",
    "        ys       = torch.cat([ys, next_tok], dim=1)\n",
    "\n",
    "        if (next_tok == trg_vocab[C.EOS_WORD]).all():\n",
    "            break\n",
    "\n",
    "    # EOS 앞까지 잘라 BOS 제외\n",
    "    results = []\n",
    "    for row in ys:\n",
    "        seq = row.tolist()\n",
    "        if C.EOS_WORD in seq:\n",
    "            seq = seq[1:seq.index(C.EOS_WORD)]\n",
    "        else:\n",
    "            seq = seq[1:]\n",
    "        results.append(seq)\n",
    "    return results\n",
    "\n",
    "# ────────────────────────────────\n",
    "# 3. Beam-search Translator (Batch-First)\n",
    "#    * Translator 구현이 batch-first 버전을 이미 지원한다고 가정\n",
    "# ────────────────────────────────\n",
    "beam_trans = Translator(\n",
    "    model=transformer,\n",
    "    beam_size=opt.beam_size,\n",
    "    max_seq_len=opt.max_token_seq_len,\n",
    "    src_pad_idx=opt.src_pad_idx,\n",
    "    trg_pad_idx=opt.trg_pad_idx,\n",
    "    trg_bos_idx=trg_vocab[C.BOS_WORD],\n",
    "    trg_eos_idx=trg_vocab[C.EOS_WORD],\n",
    ").to(device)\n",
    "\n",
    "# ────────────────────────────────\n",
    "# 4. 샘플 5개 번역\n",
    "# ────────────────────────────────\n",
    "print(\"\\n[Sample Translation Results]\")\n",
    "\n",
    "pad, bos, eos = (\n",
    "    src_vocab[C.PAD_WORD],\n",
    "    trg_vocab[C.BOS_WORD],\n",
    "    trg_vocab[C.EOS_WORD],\n",
    ")\n",
    "\n",
    "for src_B_L, trg_B_L in test_DL:      # (B,L)\n",
    "    src_B_L, trg_B_L = src_B_L.to(device), trg_B_L.to(device)\n",
    "\n",
    "    for i in range(min(5, src_B_L.size(0))):\n",
    "        src_seq = src_B_L[i:i+1]     # (1,L)\n",
    "        trg_seq = trg_B_L[i:i+1]\n",
    "\n",
    "        # 문자열 변환\n",
    "        src_txt  = [src_idx2word[t.item()] for t in src_seq[0] if t.item() != pad]\n",
    "        gold_txt = [trg_idx2word[t.item()] for t in trg_seq[0]\n",
    "                    if t.item() not in (pad, bos, eos)]\n",
    "\n",
    "        # Greedy\n",
    "        g_ids = greedy_decode_bf(transformer, src_seq, opt, device)[0]\n",
    "        g_txt = [trg_idx2word[t] for t in g_ids]\n",
    "\n",
    "        # Beam\n",
    "        b_ids = beam_trans.translate_sentence(src_seq)\n",
    "        b_txt = [trg_idx2word[t] for t in b_ids if t != eos]\n",
    "\n",
    "        print(f\"🔹 Source                    : {' '.join(src_txt)}\")\n",
    "        print(f\"🔸 Prediction (Greedy)       : {' '.join(g_txt)}\")\n",
    "        print(f\"🌟 Prediction (Beam-{opt.beam_size}) : {' '.join(b_txt)}\")\n",
    "        print(f\"✅ Ground-Truth              : {' '.join(gold_txt)}\")\n",
    "        print(\"-\" * 100)\n",
    "    break   # 첫 배치 5개만\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
