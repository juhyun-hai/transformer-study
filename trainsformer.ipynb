{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    대분류 소분류       상황  Set Nr.  발화자                            원문  \\\n",
      "0  비즈니스  회의  의견 교환하기        1  A-1   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
      "1  비즈니스  회의  의견 교환하기        1  B-1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
      "2  비즈니스  회의  의견 교환하기        1  A-2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
      "3  비즈니스  회의  의견 교환하기        1  B-2   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
      "4  비즈니스  회의  의견 교환하기        2  A-1   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
      "\n",
      "                                                 번역문  \n",
      "0  How is the market's reaction to the newly rele...  \n",
      "1  The sales increase is faster than the previous...  \n",
      "2  Then, we'll have to call the manufacturer and ...  \n",
      "3  Sure, I'll make a call and double the volume o...  \n",
      "4  Shall we take a look at the issues we discusse...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"./Korean-English/2_대화체.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, '원문'], self.data.loc[idx, '번역문']\n",
    "\n",
    "custom_DS = CustomDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] PositionalEncoding  \n",
    "[2] MultiHeadAttention  \n",
    "[3] FeedForward  \n",
    "[4] EncoderLayer  \n",
    "[5] DecoderLayer  \n",
    "[6] Encoder  \n",
    "[7] Decoder  \n",
    "[8] Transformer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.Models import Transformer\n",
    "from transformer.Optim import ScheduledOptim\n",
    "from utils.argument_parser import get_args\n",
    "import os\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_src(src, pad_idx):\n",
    "    src = src.transpose(0, 1)\n",
    "    return src\n",
    "\n",
    "\n",
    "def patch_trg(trg, pad_idx):\n",
    "    trg = trg.transpose(0, 1)\n",
    "    trg, gold = trg[:, :-1], trg[:, 1:].contiguous().view(-1)\n",
    "    return trg, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = get_args()\n",
    "opt.cuda = not opt.no_cuda\n",
    "opt.d_word_vec = opt.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] The warmup steps may be not enough.\n",
      "(sz_b, warmup) = (2048, 4000) is the official setting.\n",
      "Using smaller batch w/o longer warmup may cause the warmup stage ends with only little data trained.\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "if opt.seed is not None:\n",
    "    torch.manual_seed(opt.seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.set_deterministic(True)\n",
    "    np.random.seed(opt.seed)\n",
    "    random.seed(opt.seed)\n",
    "\n",
    "if not opt.output_dir:\n",
    "    print('No experiment result will be saved.')\n",
    "\n",
    "if not os.path.exists(opt.output_dir):\n",
    "    os.makedirs(opt.output_dir)\n",
    "\n",
    "if opt.batch_size < 2048 and opt.n_warmup_steps <= 4000:\n",
    "    print('[Warning] The warmup steps may be not enough.\\n'\\\n",
    "            '(sz_b, warmup) = (2048, 4000) is the official setting.\\n'\\\n",
    "            'Using smaller batch w/o longer warmup may cause '\\\n",
    "            'the warmup stage ends with only little data trained.')\n",
    "\n",
    "device = torch.device('cuda' if opt.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer.Constants as Constants\n",
    "\n",
    "# 1. 전체 문장 모으기\n",
    "all_src_sentences = [custom_DS[i][0] for i in range(len(custom_DS))]\n",
    "all_trg_sentences = [custom_DS[i][1] for i in range(len(custom_DS))]\n",
    "\n",
    "# 2. Tokenize (공백 기준으로 단어 분리)\n",
    "src_tokens = [token for sent in all_src_sentences for token in sent.split()]\n",
    "trg_tokens = [token for sent in all_trg_sentences for token in sent.split()]\n",
    "\n",
    "# 3. Special tokens\n",
    "special_tokens = [Constants.PAD_WORD, Constants.BOS_WORD, Constants.EOS_WORD, Constants.UNK_WORD]\n",
    "\n",
    "# 4. Vocab 만들기\n",
    "src_vocab = {token: idx for idx, token in enumerate(special_tokens + sorted(set(src_tokens)))}\n",
    "trg_vocab = {token: idx for idx, token in enumerate(special_tokens + sorted(set(trg_tokens)))}\n",
    "\n",
    "# 5. idx2word 매핑\n",
    "src_idx2word = {idx: word for word, idx in src_vocab.items()}\n",
    "trg_idx2word = {idx: word for word, idx in trg_vocab.items()}\n",
    "\n",
    "# 6. opt 세팅\n",
    "max_src_len = max(len(sent.split()) for sent in all_src_sentences)\n",
    "max_trg_len = max(len(sent.split()) for sent in all_trg_sentences)\n",
    "opt.max_token_seq_len = max(max_src_len, max_trg_len) + 2\n",
    "\n",
    "opt.src_pad_idx = src_vocab[Constants.PAD_WORD]\n",
    "opt.trg_pad_idx = trg_vocab[Constants.PAD_WORD]\n",
    "opt.src_vocab_size = len(src_vocab)\n",
    "opt.trg_vocab_size = len(trg_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split\n",
    "total_size = len(custom_DS)\n",
    "train_size = int(total_size * 0.8)\n",
    "val_size = int(total_size * 0.1)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(custom_DS, [train_size, val_size, test_size])\n",
    "\n",
    "# 2. collate_fn\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    \n",
    "    src_indices = []\n",
    "    trg_indices = []\n",
    "    for src_sent, trg_sent in zip(src_batch, trg_batch):\n",
    "        src = [src_vocab.get(token, src_vocab[Constants.UNK_WORD]) for token in src_sent.split()]\n",
    "        trg = [trg_vocab.get(token, trg_vocab[Constants.UNK_WORD]) for token in trg_sent.split()]\n",
    "\n",
    "        src = [src_vocab[Constants.BOS_WORD]] + src + [src_vocab[Constants.EOS_WORD]]\n",
    "        trg = [trg_vocab[Constants.BOS_WORD]] + trg + [trg_vocab[Constants.EOS_WORD]]\n",
    "\n",
    "        src_indices.append(torch.tensor(src, dtype=torch.long))\n",
    "        trg_indices.append(torch.tensor(trg, dtype=torch.long))\n",
    "\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_indices, batch_first=True, padding_value=src_vocab[Constants.PAD_WORD])\n",
    "    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_indices, batch_first=True, padding_value=trg_vocab[Constants.PAD_WORD])\n",
    "\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "# 3. DataLoader\n",
    "train_DL = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_DL = DataLoader(val_dataset, batch_size=opt.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_DL = DataLoader(test_dataset, batch_size=opt.batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    opt.src_vocab_size,\n",
    "    opt.trg_vocab_size,\n",
    "    src_pad_idx=opt.src_pad_idx,\n",
    "    trg_pad_idx=opt.trg_pad_idx,\n",
    "    trg_emb_prj_weight_sharing=opt.proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=opt.embs_share_weight,\n",
    "    d_k=opt.d_k,\n",
    "    d_v=opt.d_v,\n",
    "    d_model=opt.d_model,\n",
    "    d_word_vec=opt.d_word_vec,\n",
    "    d_inner=opt.d_inner_hid,\n",
    "    n_layers=opt.n_layers,\n",
    "    n_head=opt.n_head,\n",
    "    dropout=opt.dropout,\n",
    "    scale_emb_or_prj=opt.scale_emb_or_prj).to(device)\n",
    "\n",
    "optimizer = ScheduledOptim(\n",
    "        optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "        opt.lr_mul, opt.d_model, opt.n_warmup_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def cal_performance(pred, gold, pad_idx):\n",
    "    gold = gold.contiguous().view(-1)\n",
    "    pred = pred.view(-1, pred.size(-1))\n",
    "    \n",
    "    non_pad_mask = gold.ne(pad_idx)\n",
    "    n_correct = pred.max(1)[1].eq(gold).masked_select(non_pad_mask).sum().item()\n",
    "    n_word = non_pad_mask.sum().item()\n",
    "\n",
    "    loss = F.cross_entropy(pred, gold, ignore_index=pad_idx, reduction='sum')\n",
    "    return loss, n_correct, n_word\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, opt, device):\n",
    "    ''' 한 epoch 동안 학습하는 함수 (tqdm 추가 버전) '''\n",
    "    model.train()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
    "\n",
    "    desc = '  - (Training)   '\n",
    "    for src_seq, trg_seq in tqdm(train_loader, mininterval=2, desc=desc, leave=False):\n",
    "        src_seq = src_seq.to(device)\n",
    "        trg_seq = trg_seq.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # decoder input은 trg_seq의 BOS ~ 마지막 단어 직전까지\n",
    "        # gold는 trg_seq의 첫 단어 이후 ~ EOS까지\n",
    "        gold = trg_seq[:, 1:]\n",
    "        trg_seq = trg_seq[:, :-1]\n",
    "\n",
    "        pred = model(src_seq, trg_seq)\n",
    "\n",
    "        loss, n_correct, n_word = cal_performance(pred, gold, opt.trg_pad_idx)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step_and_update_lr()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_word_total += n_word\n",
    "        n_word_correct += n_correct\n",
    "\n",
    "    loss_per_word = total_loss / n_word_total\n",
    "    accuracy = n_word_correct / n_word_total\n",
    "    return loss_per_word, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, opt, device):\n",
    "    ''' 한 epoch 동안 검증하는 함수 '''\n",
    "    model.eval()\n",
    "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src_seq, trg_seq in val_loader:\n",
    "            src_seq = src_seq.to(device)\n",
    "            trg_seq = trg_seq.to(device)\n",
    "\n",
    "            gold = trg_seq[:, 1:]\n",
    "            trg_seq = trg_seq[:, :-1]\n",
    "\n",
    "            pred = model(src_seq, trg_seq)\n",
    "\n",
    "            loss, n_correct, n_word = cal_performance(pred, gold, opt.trg_pad_idx)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_word_total += n_word\n",
    "            n_word_correct += n_correct\n",
    "\n",
    "    loss_per_word = total_loss / n_word_total\n",
    "    accuracy = n_word_correct / n_word_total\n",
    "    return loss_per_word, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch_i in range(opt.epoch):\n",
    "    print(f'[ Epoch {epoch_i} ]')\n",
    "\n",
    "    start = time.time()\n",
    "    train_loss, train_accu = train_epoch(transformer, train_DL, optimizer, opt, device)\n",
    "    print('  - (Training)   loss: {:.5f}, accuracy: {:.3f} %, elapse: {:.3f} min'.format(\n",
    "        train_loss, 100*train_accu, (time.time()-start)/60))\n",
    "\n",
    "    start = time.time()\n",
    "    val_loss, val_accu = eval_epoch(transformer, val_DL, opt, device)\n",
    "    print('  - (Validation) loss: {:.5f}, accuracy: {:.3f} %, elapse: {:.3f} min'.format(\n",
    "        val_loss, 100*val_accu, (time.time()-start)/60))\n",
    "\n",
    "    # 모델 저장\n",
    "    checkpoint = {\n",
    "        'epoch': epoch_i,\n",
    "        'model': transformer.state_dict(),\n",
    "        'opt': opt,\n",
    "        'src_vocab': src_vocab,\n",
    "        'trg_vocab': trg_vocab\n",
    "    }\n",
    "    torch.save(checkpoint, f'{opt.output_dir}/transformer_epoch{epoch_i}.chkpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터 샘플 5개 번역해보기\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "def greedy_decode(model, src_seq, opt, device):\n",
    "    model.eval()\n",
    "    src_seq = src_seq.unsqueeze(0).to(device)  # (batch=1)\n",
    "    src_mask = (src_seq != opt.src_pad_idx).unsqueeze(-2)\n",
    "\n",
    "    enc_output, *_ = model.encoder(src_seq, src_mask)\n",
    "\n",
    "    # 초기 입력은 BOS 토큰\n",
    "    dec_input = torch.LongTensor([[opt.trg_pad_idx]]).fill_(trg_vocab[Constants.BOS_WORD]).to(device)\n",
    "\n",
    "    pred_tokens = []\n",
    "    for _ in range(opt.max_token_seq_len):\n",
    "        dec_mask = (dec_input != opt.trg_pad_idx).unsqueeze(-2) & get_subsequent_mask(dec_input)\n",
    "        dec_output, *_ = model.decoder(dec_input, dec_mask, enc_output, src_mask)\n",
    "        seq_logit = model.trg_word_prj(dec_output)\n",
    "        next_word = seq_logit[:, -1, :].argmax(-1)\n",
    "        pred_tokens.append(next_word.item())\n",
    "        dec_input = torch.cat([dec_input, next_word.unsqueeze(0)], dim=1)\n",
    "        if next_word.item() == trg_vocab[Constants.EOS_WORD]:\n",
    "            break\n",
    "    return pred_tokens\n",
    "\n",
    "# 5개 출력\n",
    "print(\"\\n[Sample Translation Results]\")\n",
    "for src_seq, trg_seq in list(test_DL)[:1]:   # batch 하나 가져오기\n",
    "    src_seq = src_seq.to(device)\n",
    "    for i in range(5):\n",
    "        src_tokens = [src_idx2word[idx.item()] for idx in src_seq[i] if idx.item() != src_vocab[Constants.PAD_WORD]]\n",
    "        pred_idx_seq = greedy_decode(model, src_seq[i], opt, device)\n",
    "        pred_tokens = [trg_idx2word[idx] for idx in pred_idx_seq]\n",
    "\n",
    "        print(f\"Source: {' '.join(src_tokens)}\")\n",
    "        print(f\"Predicted Translation: {' '.join(pred_tokens)}\")\n",
    "        print(\"-\" * 50)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
